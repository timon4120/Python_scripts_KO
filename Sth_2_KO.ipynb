{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service #Chromedriver.exe is required for the application to work properly!\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re, io, json, os \n",
    "import networkx as nx\n",
    "import networkit as nk\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_links(driver):\n",
    "    links = []\n",
    "    webdom = [\"fizyka.pw.edu\",\"if.pw.edu\"] #List of substrings which must be included in our URL, for instance only certain domain description. \n",
    "    elements = driver.find_elements(By.TAG_NAME,'a')\n",
    "    for elem in elements:\n",
    "        href = elem.get_attribute(\"href\")\n",
    "        if href == None: continue\n",
    "        types = [] \n",
    "        if ((webdom[0] in href or webdom[1] in href) and (\".pdf\" not in href) and (\".jpg\" not in href)):\n",
    "            links.append(href)\n",
    "    links = np.array(links)\n",
    "    links = links[links != np.array(None)]\n",
    "    links = np.unique(links)\n",
    "    return links"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--disable-notifications')\n",
    "service = Service('./chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = service, options=options)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link extraction within single pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_dict = {}\n",
    "supp = []\n",
    "DF = pd.read_csv(\"WWW.csv\", encoding = \"ISO-8859-1\") #WWW.csv - file containing webpages URLs\n",
    "my_all_links = list(DF[\"URL\"].astype(str))\n",
    "\n",
    "# my_all_links = [] #Alternative direct list of certain websites\n",
    "for i,link in enumerate(my_all_links):  \n",
    "    if not \"http\" in link: link = \"https://\" + link\n",
    "    driver.get(link)\n",
    "    curr = driver.current_url\n",
    "    print(f\"CURR: {curr} ----> OK\")\n",
    "    try:\n",
    "        global_dict[curr] = get_all_links(driver)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=======================================================================================\")\n",
    "print(\"============================Extracting links within domain=============================\")\n",
    "print(\"=======================================================================================\")\n",
    "\n",
    "cnt = 0\n",
    "while True:\n",
    "    glob_key = list(global_dict.keys())[cnt]\n",
    "    glob = global_dict[glob_key]\n",
    "    if len(glob) == 0: \n",
    "        cnt += 1\n",
    "        continue\n",
    "    else:\n",
    "        if \"if.pw\" in glob_key:\n",
    "            m = re.search('~(.+?)/', glob_key)\n",
    "            mm = m[0][1:-1]\n",
    "        elif \"fizyka.pw\" in glob_key:\n",
    "            mm = glob_key[:glob_key.index(\"fizyka\")-1]\n",
    "        else:\n",
    "            mm = glob_key\n",
    "        for i in glob:\n",
    "            if mm in i:\n",
    "                try:\n",
    "                    driver.get(i)\n",
    "                    global_dict[glob_key] = np.append(global_dict[glob_key],get_all_links(driver))\n",
    "                except: continue\n",
    "            else: continue  \n",
    "        global_dict[glob_key] = list(filter(lambda x: mm not in x,global_dict[glob_key]))\n",
    "        global_dict[glob_key] = np.array(global_dict[glob_key])\n",
    "        global_dict[glob_key] = np.unique(global_dict[glob_key])\n",
    "        cnt += 1\n",
    "        print(\"==========\")\n",
    "    if cnt == len(global_dict): break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in global_dict:\n",
    "    global_dict[i] = global_dict[i].tolist()\n",
    "\n",
    "with open(f\"data.json\",\"w\") as f:\n",
    "    json.dump(global_dict,f,indent=6) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data from JSON & DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.json\",\"r\") as f:\n",
    "    XC = json.load(f)\n",
    "\n",
    "Big_joe = []  \n",
    "for i,j in XC.items():\n",
    "    for k in j:\n",
    "        Big_joe.append([i,k])\n",
    "\n",
    "XX = pd.DataFrame(Big_joe, columns=[\"WWW1\",\"WWW2\"])\n",
    "XX.to_csv(\"data.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network creation and visualization\n",
    "This method is quite primitive. You'd better use some other special programs like Cytoscape, GePhi etc. to create nice visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from(XX.values)\n",
    "list_degree=list(G.degree()) \n",
    "nodes , degree = map(list, zip(*list_degree)) \n",
    "plt.figure(figsize=(10,10))\n",
    "nx.draw(G, nodelist=nodes, with_labels = True, node_size=[(v * 20)+1 for v in degree], node_color = \"yellow\", pos=nx.nx_agraph.graphviz_layout(G,\"fdp\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5acd694a927ad2c0c64659d7f035b2992c50a9e4b0f868fb6bbfaf28ed4b3b0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
